{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d667b4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Full extraction: Loaded ALL 325 records.\n",
      "Sample data generated in school_attendance.csv\n",
      "\n",
      "Found 0 new records since 2018-11-30T22:00:00\n",
      "Returning 0 records (max 50)\n",
      "\n",
      "No new records found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "\n",
    "#\n",
    "# SECTION 1: GENERATE SAMPLE DATA\n",
    "#\n",
    "\n",
    "# Only try to load the CSV if it exists and has the required columns\n",
    "if os.path.exists(\"school_attendance.csv\"):\n",
    "    temp_df = pd.read_csv(\"school_attendance.csv\")\n",
    "    if \"last_updated\" in temp_df.columns:\n",
    "        df = pd.read_csv(\n",
    "            \"school_attendance.csv\",\n",
    "            parse_dates=[\"last_updated\"],\n",
    "            converters={\"Date\": lambda x: datetime.strptime(x, \"%Y%m%d\")}\n",
    "        )\n",
    "        print(f\" Full extraction: Loaded ALL {len(df)} records.\")\n",
    "    else:\n",
    "        print(\"school_attendance.csv exists but is missing 'last_updated' column. Please generate sample data first.\")\n",
    "        df = None\n",
    "else:\n",
    "    print(\"school_attendance.csv not found. Please generate sample data first.\")\n",
    "    df = None\n",
    "# You can assign to a variable if needed, e.g. df_full = df\n",
    "# except Exception as e:\n",
    "# print(f\" # school_attendance_etl.py\n",
    "\n",
    "\n",
    "def generate_sample_data():\n",
    "    database_file = 'school_attendance.csv'\n",
    "    schools = ['01M015', '02M394', '03K403', '04M409', '05M280']\n",
    "    data = []\n",
    "    start_date = datetime(2018, 9, 1)\n",
    "\n",
    "    for i in range(1, 91):  # 90 days of data\n",
    "            date = start_date + timedelta(days=i)\n",
    "            if date.weekday() >= 5:  # Skip weekends\n",
    "                continue\n",
    "                \n",
    "            for school in schools:\n",
    "                enrolled = random.randint(150, 200)\n",
    "                absent = random.randint(5, 30)\n",
    "                present = enrolled - absent\n",
    "                data.append({\n",
    "                    'School DBN': school,\n",
    "                    'Date': date.date().strftime('%Y%m%d'),\n",
    "                    'Enrolled': enrolled,\n",
    "                    'Absent': absent,\n",
    "                    'Present': present,\n",
    "                    'Released': 0,\n",
    "                    'last_updated': (date + timedelta(hours=random.randint(0, 23))).isoformat()\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('school_attendance.csv', index=False)\n",
    "print(\"Sample data generated in school_attendance.csv\")\n",
    "\n",
    "#\n",
    "# SECTION 2 FULL EXTRACTION AND TRANSFORMATION\n",
    "# try:Full extraction failed: {str(e)}\")\n",
    "df = None  # or df_full = None\n",
    "\n",
    "#INCREMENTAL EXTRACTION\n",
    "def incremental_extraction(max_rows=50):\n",
    "    \"\"\"Perform incremental extraction with row limit\"\"\"\n",
    "    try:\n",
    "        # 1. Handle last_extraction.txt\n",
    "        if not os.path.exists(\"last_extraction.txt\"):\n",
    "            with open(\"last_extraction.txt\", \"w\") as f:\n",
    "                default_date = \"2018-01-01T00:00:00\"\n",
    "                f.write(default_date)\n",
    "            print(f\"Created last_extraction.txt with default date {default_date}\")\n",
    "        \n",
    "        with open(\"last_extraction.txt\", \"r\") as f:\n",
    "            last_extraction = f.read().strip()\n",
    "\n",
    "        # 2. Load and process data\n",
    "        df = pd.read_csv(\"school_attendance.csv\", \n",
    "                        parse_dates=[\"last_updated\"],\n",
    "                        converters={'Date': lambda x: datetime.strptime(x, '%Y%m%d')})\n",
    "        \n",
    "        last_extraction_time = pd.to_datetime(last_extraction)\n",
    "        df_incremental = df[df['last_updated'] > last_extraction_time]\n",
    "        \n",
    "        # 3. Apply row limit\n",
    "        df_limited = df_incremental.head(max_rows)\n",
    "        \n",
    "        print(f\"\\nFound {len(df_incremental)} new records since {last_extraction}\")\n",
    "        print(f\"Returning {len(df_limited)} records (max {max_rows})\")\n",
    "        \n",
    "        if len(df_limited) > 0:\n",
    "            print(\"\\nSample of returned records:\")\n",
    "            print(df_limited.head())\n",
    "            \n",
    "            # 4. Update timestamp\n",
    "            new_checkpoint = df_limited['last_updated'].max()\n",
    "            with open(\"last_extraction.txt\", \"w\") as f:\n",
    "                f.write(new_checkpoint.isoformat())\n",
    "            print(f\"\\nUpdated last_extraction.txt to {new_checkpoint}\")\n",
    "            \n",
    "            return df_limited\n",
    "        else:\n",
    "            print(\"\\nNo new records found.\")\n",
    "            return pd.DataFrame()  # Return empty DataFrame if no new records\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate sample data if needed\n",
    "    generate_sample_data()\n",
    "    \n",
    "    # Run incremental extraction (gets max 50 rows)\n",
    "    result = incremental_extraction(max_rows=50)\n",
    "    \n",
    "    # Optional: Save the extracted data to a new file\n",
    "    if result is not None and not result.empty:\n",
    "        result.to_csv(\"latest_extracted_records.csv\", index=False)\n",
    "        print(\"\\nSaved extracted records to latest_extracted_records.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "935ac738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 0 new records since 2018-11-30T22:00:00\n",
      "Returning 0 records (max 50)\n",
      "\n",
      "No new records found.\n",
      "\n",
      "No new records found.\n"
     ]
    }
   ],
   "source": [
    "# Run incremental extraction and print results\n",
    "df_incremental = incremental_extraction(max_rows=50)\n",
    "\n",
    "if df_incremental is not None and not df_incremental.empty:\n",
    "    print(f\"\\nFound {len(df_incremental)} new records.\")\n",
    "    print(\"\\nSample of returned records:\")\n",
    "    print(df_incremental.head())\n",
    "else:\n",
    "    print(\"\\nNo new records found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9ed4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full extraction: Loaded ALL 325 records.\n",
      "Full extraction failed: name 'transform_data' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_full = pd.read_csv(\n",
    "        \"school_attendance.csv\",\n",
    "        parse_dates=[\"last_updated\"],\n",
    "        converters={\"Date\": lambda x: datetime.strptime(x, \"%Y%m%d\")}\n",
    "    )\n",
    "    print(f\"Full extraction: Loaded ALL {len(df_full)} records.\")\n",
    "    transform_data(df_full, \"transformed_full.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Full extraction failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c389faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result is not None and not result.empty:\n",
    "    result.to_csv(\"latest_extracted_records.csv\", index=False)\n",
    "    print(\"Saved extracted records to latest_extracted_records.csv\")\n",
    "\n",
    "    # Transforming incremental data\n",
    "    transform_data(result, \"transformed_incremental.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e383f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded full dataset with 325 records.\n",
      "Transformed full dataset saved to transformed_full.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Transforming Full Data ---\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def transform_data(df, output_path):\n",
    "    \"\"\"\n",
    "    Apply cleaning, enrichment, and structural transformation to the dataset.\n",
    "    Saves the transformed data to output_path.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(\"No data to transform.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 1. Cleaning: Remove duplicates and fill missing values\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # 2. Enrichment: Add attendance rate as a percentage\n",
    "    df['Attendance_Rate'] = (df['Present'] / df['Enrolled']) * 100\n",
    "\n",
    "    # 3. Structural: Standardize 'Date' format and school codes\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d')\n",
    "    df['School DBN'] = df['School DBN'].str.upper()\n",
    "\n",
    "    # Save transformed data\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Transformed full dataset saved to {output_path}\")\n",
    "    return df\n",
    "\n",
    "# Load full extracted data\n",
    "try:\n",
    "    df_full = pd.read_csv(\n",
    "        \"school_attendance.csv\",\n",
    "        parse_dates=[\"last_updated\"],\n",
    "        converters={\"Date\": lambda x: datetime.strptime(x, \"%Y%m%d\")}\n",
    "    )\n",
    "    print(f\"Loaded full dataset with {len(df_full)} records.\")\n",
    "\n",
    "    # Transform full dataset\n",
    "    df_transformed_full = transform_data(df_full, \"transformed_full.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in full data transformation: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2160fc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded incremental dataset with 3 records.\n",
      "Transformed full dataset saved to transformed_incremental.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Transform Incremental Data ---\n",
    "\n",
    "try:\n",
    "    # Load incremental data (no need for converters if date is already in ISO format)\n",
    "    df_incremental = pd.read_csv(\n",
    "        \"latest_extracted_records.csv\",\n",
    "        parse_dates=[\"Date\", \"last_updated\"]\n",
    "    )\n",
    "    print(f\"Loaded incremental dataset with {len(df_incremental)} records.\")\n",
    "\n",
    "    # Transform incremental dataset\n",
    "    df_transformed_incremental = transform_data(df_incremental, \"transformed_incremental.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in incremental data transformation: {str(e)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
